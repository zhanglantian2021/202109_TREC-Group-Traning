#plot the data with separate colours for each fish type
plot(fishspeed $Temperature, fishspeed $Speed,col= c("red", "blue")[as.numeric(fishspeed $Species)])
lm1 <- lm(Speed~Temperature*Species,fishspeed)
summary(lm1)
lm1 <- lm(Speed~Species*Temperature,fishspeed)
summary(lm1)
lm1 <- lm(Speed~Temperature*Temperature,fishspeed)
summary(lm1)
lm1 <- lm(Speed~Temperature*Species,fishspeed)
summary(lm1)
#check anova as well
anova(lm1)
# plot the line of fitted values
plot(fishspeed $Temperature,lm1$fitted,ylab="Fish speed",xlab="Temperature")
# add the scatter plot points
points(fishspeed $Temperature,fishspeed $Speed,pch=3,col="blue")
fishspeed2 <-read.table(file="fishspeed2.csv",header=T,row.names=NULL,sep=",")
summary(fishspeed2)
lm1 <- lm(Speed~Temperature*Species,fishspeed2)
summary(lm1)
summary(fishspeed2)
fishspeed2$Species <- as.factor(fishspeed2$Species)
summary(fishspeed2)
lm1 <- lm(Speed~Temperature*Species,fishspeed2)
summary(lm1)
fishspeed2$Species <- relevel(fishspeed2$Species,ref="Trout")
lm1 <- lm(Speed~Temperature*Species,fishspeed2)
summary(lm1)
fishspeed2$Species <- relevel(fishspeed2$Species,ref="Galaxias")
levels(fishspeed2$Species)
#rerun the model
#....
#following this it would make sense to combine values of Trout and Tenebrias to get a better common estimate using the combined data
levels(fishspeed2$Species) <- c("Galaxias", "TT", "TT")
lm1 <- lm(Speed~Temperature*Species,fishspeed2)
summary(lm1)
fishspeed2 <-read.table(file="fishspeed2.csv",header=T,row.names=NULL,sep=",")
summary(fishspeed2)
fishspeed2$Species <- as.factor(fishspeed2$Species)
summary(fishspeed2)
levels(fishspeed2$Species)
b0 <- c(rep(1,dim(fishspeed2)[1]))
b0
b1 <- fishspeed2$Temperature
# we need a column of 1's for the intercept of same length as the number of rows in the fishspeed data
# to get intercept repeat values of 1 n times
fishspeed2$Species
# we need a column of 1's for the intercept of same length as the number of rows in the fishspeed data
# to get intercept repeat values of 1 n times
summary(fishspeed2)
fishspeed2$Species
b2 <- c(rep(1,10),rep(0,8),rep(0,11))
b3 <- c(rep(0,10),rep(0,8),rep(1,11))
b0 <- c(rep(1,dim(fishspeed2)[1]))
b1 <- fishspeed2$Temperature
b2 <- c(rep(1,10),rep(0,8),rep(0,11))
b3 <- c(rep(0,10),rep(0,8),rep(1,11))
b4 <- b1*b2
b5 <- b1*b3
X <- data.frame(b0,b1,b2,b3,b4,b5)
X <- as.matrix(X)
X
y <- fishspeed$Speed
#create transpose
Xt <- t(X)
y <- fishspeed2$Speed
dim(X); dim(y)
y <- fishspeed2$Speed
dim(X); dim(y)
# we need a column of 1's for the intercept of same length as the number of rows in the fishspeed data
# to get intercept repeat values of 1 n times
summary(fishspeed2)
y <- fishspeed2$Speed
length(y)
dim(X)
#create transpose
Xt <- t(X)
dim(X);dim(Xt)
#multiply Xt by X using MATRIX MULTIPLICATION
XX <- Xt %*% X
dim(XX)
#find the inverse (X'X)-1
XXinv <- solve(XX)
XXinv
dim(XXinv)
#find X'y
Xy <- Xt%*%y
#now we have all the pieces
B <- XXinv %*% Xy
B
summary(lm(Speed~Temperature*Species,data= fishspeed2))
B
fishspeed2 <-read.table(file="fishspeed2.csv",header=T,row.names=NULL,sep=",")
lm3 <- lm(Speed~Temperature*Species,fishspeed2)
str(lm3)
par(mfrow=c(2,2))
plot(lm3)
###Assumptions###
#Normality
resids <- resid(lm3, type='pearson')
library(car)
par(mfrow=c(1,1))
qqPlot(resids)
#Shapiro test to check for non-normality (a significant test result means non-normal)
shapiro.test(residuals(lm3))
#Homoscedasticity
plot(sqrt(abs(resids))~lm3$fitted); abline(a = 1.96, b = 0, col = 2)
#Levene test for homogeneity of variance across groups
leveneTest(residuals(lm3), as.factor(fishspeed2$Species))
#READ IN THE DATA
# import the data "fishspeed.csv" into R and attach the data
fishspeed <-read.table(file="fishspeed.csv",header=T,row.names=NULL,sep=",")
summary(fishspeed)
dim(fishspeed)
fishspeed$Species <- as.factor(fishspeed$Species)
summary(lm(Speed~Temperature,data= fishspeed))
summary(lm(Speed~Species,data= fishspeed))
t.test(Speed~Species,data= fishspeed,var.equal = TRUE)
dim(fishspeed)[1]
b0 <- c(rep(1,dim(fishspeed)[1]))
b0
b1 <- fishspeed$Temperature
X <- data.frame(b0,b1)
X <- as.matrix(X)
X
y <- fishspeed$Speed
#create transpose
Xt <- t(X)
dim(X);dim(Xt)
#multiply Xt by X using MATRIX MULTIPLICATION
XX <- Xt %*% X
dim(XX)
#find the inverse (X'X)-1
XXinv <- solve(XX)
XXinv
#find X'y
Xy <- Xt%*%y
#now we have all the pieces
B <- XXinv %*% Xy
B
summary(lm(Speed~Temperature,data= fishspeed))
# vector for b0 does not change
b0 <- c(rep(1,dim(fishspeed)[1]))
# but for a factor you need to use a dummy variate to represent the different cases of fish species
#so lets check how many we have of each fish species
fishspeed$Species
#so first 10 values are trout and next 8 are galaxias
b1 <- c(rep(0,10),rep(1,8))
X <- data.frame(b0,b1)
b1
X <- data.frame(b0,b1)
X <- as.matrix(X)
X
y <- fishspeed$Speed
#create transpose
Xt <- t(X)
#multiply Xt by X using MATRIX MULTIPLICATION
XX <- Xt %*% X
#find the inverse (X'X)-1
XXinv <- solve(XX)
#find X'y
Xy <- Xt%*%y
#now we have all the pieces
B <- XXinv %*% Xy
B
summary(lm(Speed~Species,data= fishspeed))
fishspeed$Species <- relevel(fishspeed$Species,ref="Trout")
yt <- t(y)
yy <- yt %*% y
Bt <- t(B)
BXy <- Bt %*% Xy
n= dim(fishspeed)[1]
p=2
res.var <- (yy - BXy)*(1/(n-p))
res.var
sqrt(res.var)   # residual standard error
#compare with lm() result; look at the residual standard error
summary(lm(Speed~Species,data= fishspeed))
#plot the data with separate colours for each fish type
plot(fishspeed $Temperature, fishspeed $Speed,col= c("red", "blue")[as.numeric(fishspeed $Species)])
lm3 <- lm(Speed~Temperature*Species,fishspeed2)
fishspeed2 <-read.table(file="fishspeed2.csv",header=T,row.names=NULL,sep=",")
summary(fishspeed2)
lm3 <- lm(Speed~Temperature*Species,fishspeed2)
summary(lm3)
str(lm3)
par(mfrow=c(2,2))
plot(lm3)
library(car)
###Assumptions###
#Normality
resids <- resid(lm3, type='pearson')
## qq plot with 95% CIs
par(mfrow=c(1,1))
qqPlot(resids)
#Shapiro test to check for non-normality (a significant test result means non-normal)
shapiro.test(residuals(lm3))
#Homoscedasticity
plot(sqrt(abs(resids))~lm3$fitted); abline(a = 1.96, b = 0, col = 2)
#Levene test for homogeneity of variance across groups
leveneTest(residuals(lm3), as.factor(fishspeed2$Species))
library(tidyverse)
library(see)
library(see)
install.packages("see")
library(see)
pp_check(lm3)%>%plot()
library(see)
pp_check(lm3)%>%plot()
check_model(lm3)
lm3
pp_check(lm3)%>%plot()
check_model(lm3)
library(performance)
pp_check(lm3)%>%plot()
check_model(lm3)
check_model(lm3)
library(tidyverse)
library(see)
library(performance)
pp_check(lm3)%>%plot()
check_model(lm3)
lm3
check_model(lm3)
setwd("E:/16培训班/2021年6月14-19日线性混合模型/Lesson2/Lesson 2 Generalised linear models")
library(ggplot2)
seal <- read.csv('sealData1.csv', h=T)
summary(seal)
head(seal)
dim(seal)
head(seal)
summary(seal)
seal <- read.csv('sealData1.csv', h=T)
summary(seal)
seal
summary(seal)
head(seal)
dim(seal)
plot(n.response/n.obs~pupage,data=seal)
## fit the binomial model from the first day
mod.seal <- glm(cbind(n.response, n.obs-n.response)~pupage,
data=seal,family=binomial(link=logit))
summary(mod.seal)
mod.seal1 <- glm(cbind(n.response, n.obs-n.response)~pupage,
data=seal,family=binomial)
summary(mod.seal1)
mod.seal <- glm(cbind(n.response, n.obs-n.response)~pupage,
data=seal,family=binomial(link=logit))
summary(mod.seal)
summary(seal)
## build new data frame to house predictions
##it should cover the same range as the values you have recorded in oberevations
newdata <- data.frame(pupage=1:30)
newdata
summary(mod.seal)
## make the predictions - notice the type='link' argument
preds <- predict(mod.seal, newdata=newdata,type= 'link', se.fit=T)
preds #the command produces a fitted value with standard error for each predictor value in newdata
summary(seal)
dim(seal)
newdata$fit_T <- preds$fit
newdata$upr_T <- preds$fit+preds$se.fit*1.96
newdata$lwr_T <- preds$fit-preds$se.fit*1.96
## plot with prediction in the transformed range
plot(newdata$pupage,newdata$fit_T,type="l")
lines(newdata$pupage,newdata$upr_T,lty=2)
lines(newdata$pupage,newdata$lwr_T,lty=2)
head(newdata)
newdata$fit <- plogis(preds$fit)
newdata$upr <- plogis(preds$fit+preds$se.fit*1.96)
newdata$lwr <- plogis(preds$fit-preds$se.fit*1.96)
head(newdata) #note the extra columns in the dataframe
str(newdata)
## plot raw data and model prediction in the response range
#for this we will use ggplot
ggplot(data=seal, aes(x=pupage, y=n.response/n.obs)) + geom_point()+
geom_smooth(data=newdata,aes(x=pupage, y=fit, ymin=lwr, ymax=upr),
stat='identity')
## fit the tested model: aggression ~ pupage
mod.seal1 <- glm(cbind(n.response, n.obs-n.response)~pupage, data=seal,family=binomial)
summary(mod.seal1)
# residual and null deviance estimates provided at the bottom for tested and null models respectively
logLik(mod.seal1)
## fit the null model: aggression ~ 1
mod.seal0 <- glm(cbind(n.response, n.obs-n.response)~1, data=seal,family=binomial)
summary(mod.seal0)
# residual and null deviances are identical
logLik(mod.seal0)
#how to get a saturated model? A saturated model has one parameter for each data point
#we can make a dummy to carry this
seal $x1 <- as.factor(1:nrow(seal))
summary(seal)
mod.sealS <- glm(cbind(n.response, n.obs-n.response)~x1, data=seal,family=binomial)
summary(mod.sealS)
#now you can see the residual deviance for the saturated model is basically zero
logLik(mod.sealS)
#so residual deviance for tested model is:
2*(logLik(mod.sealS)-logLik(mod.seal1))
#so residual deviance for null model is:
2*(logLik(mod.sealS)-logLik(mod.seal0))
#compare with output from summary(mod.seal1)
summary(mod.seal1)
#Now compare the residual and null deviances (ask whether there has been a significant reduction in the deviance caused by adding in the predictor pupage)
anova(mod.seal1,test='Chisq')
library(ggplot2)
seal <- read.csv('sealData1.csv', h=T)
summary(seal)
head(seal)
dim(seal)
plot(n.response/n.obs~pupage,data=seal)
## fit the binomial model from the first day
mod.seal <- glm(cbind(n.response, n.obs-n.response)~pupage,
data=seal,family=binomial(link=logit))
summary(mod.seal)
mod.seal1 <- glm(cbind(n.response, n.obs-n.response)~pupage,
data=seal,family=binomial)
summary(mod.seal1)
mod.seal <- glm(cbind(n.response, n.obs-n.response)~pupage,
data=seal,family=binomial(link=logit))
summary(mod.seal)
summary(seal)
## build new data frame to house predictions
##it should cover the same range as the values you have recorded in oberevations
newdata <- data.frame(pupage=1:30)
newdata
summary(mod.seal)
## make the predictions - notice the type='link' argument
preds <- predict(mod.seal, newdata=newdata,type= 'link', se.fit=T)
preds #the command produces a fitted value with standard error for each predictor value in newdata
summary(seal)
dim(seal)
newdata$fit_T <- preds$fit
newdata$upr_T <- preds$fit+preds$se.fit*1.96
newdata$lwr_T <- preds$fit-preds$se.fit*1.96
## plot with prediction in the transformed range
plot(newdata$pupage,newdata$fit_T,type="l")
lines(newdata$pupage,newdata$upr_T,lty=2)
lines(newdata$pupage,newdata$lwr_T,lty=2)
head(newdata)
newdata$fit <- plogis(preds$fit)
newdata$upr <- plogis(preds$fit+preds$se.fit*1.96)
newdata$lwr <- plogis(preds$fit-preds$se.fit*1.96)
head(newdata) #note the extra columns in the dataframe
str(newdata)
## plot raw data and model prediction in the response range
#for this we will use ggplot
ggplot(data=seal, aes(x=pupage, y=n.response/n.obs)) + geom_point()+
geom_smooth(data=newdata,aes(x=pupage, y=fit, ymin=lwr, ymax=upr),
stat='identity')
## fit the tested model: aggression ~ pupage
mod.seal1 <- glm(cbind(n.response, n.obs-n.response)~pupage, data=seal,family=binomial)
summary(mod.seal1)
# residual and null deviance estimates provided at the bottom for tested and null models respectively
logLik(mod.seal1)
## fit the null model: aggression ~ 1
mod.seal0 <- glm(cbind(n.response, n.obs-n.response)~1, data=seal,family=binomial)
summary(mod.seal0)
# residual and null deviances are identical
logLik(mod.seal0)
#how to get a saturated model? A saturated model has one parameter for each data point
#we can make a dummy to carry this
seal $x1 <- as.factor(1:nrow(seal))
summary(seal)
<- as.factor(1:nrow(seal))
seal $x1
mod.sealS <- glm(cbind(n.response, n.obs-n.response)~x1, data=seal,family=binomial)
summary(mod.sealS)
#now you can see the residual deviance for the saturated model is basically zero
logLik(mod.sealS)
#so residual deviance for tested model is:
2*(logLik(mod.sealS)-logLik(mod.seal1))
#so residual deviance for null model is:
2*(logLik(mod.sealS)-logLik(mod.seal0))
#compare with output from summary(mod.seal1)
summary(mod.seal1)
#Now compare the residual and null deviances (ask whether there has been a significant reduction in the deviance caused by adding in the predictor pupage)
anova(mod.seal1,test='Chisq')
summary(mod.sealS)
#now you can see the residual deviance for the saturated model is basically zero
logLik(mod.sealS)
#Now compare the residual and null deviances (ask whether there has been a significant reduction in the deviance caused by adding in the predictor pupage)
anova(mod.seal1,test='Chisq')
aphid2 <- read.csv('AphidData2.csv', h=T)
#check out the data
summary(aphid2) #two treatments and counts of aphids. typical poisson data
dim(aphid2)
head(aphid2)
str(aphid2)
aphid2$trt <- as.factor(aphid2$trt)
aphid2$trt <- as.factor(aphid2$trt)
mod1 <- glm(n.aphids~trt, data=aphid2, family=poisson)
summary(mod1)
par(mfrow=c(2,2)); plot(mod1)
#check for overdispersion formally
chisq <- sum(resid(mod1, type='pearson')^2)
chisq/df.residual(mod1) ## much greater than 1
## significantly so?
1-pchisq(chisq, df.residual(mod1)) ## Very significant
#include library to run the dispersiontest
library(AER)
install.packages("AER")
#include library to run the dispersiontest
library(AER)
#from the chisq residuals estimate, we know its overdispersion, so set up the test to  check for this
dispersiontest(mod1,alternative = "greater")
mod.qp <- glm(n.aphids~trt, data=aphid2, family=quasipoisson(link=log))
coef(mod.qp)
coef(mod1)
par(mfrow=c(2,2)); plot(mod1)
#quartz()  #windows people, please use "windows()" here
windows()
par(mfrow=c(2,2)); plot(mod.qp)
## looks similar to mod1
## only thing that changes is the scaling (bottom right plot)
summary(mod.qp)
summary(mod1)
anova(mod.qp, test='Chisq')
sum(resid(mod1, type='pearson')^2)/df.residual(mod1)
sum(resid(mod.qp, type='pearson')^2)/df.residual(mod.qp) ## the same
summary(mod1)$dispersion
summary(mod.qp)$dispersion ## different between models
#but look what has happened to the standard errors of the model outputs
summary(mod1)
summary(mod.qp)
#you can also test the significance of the quasipoisson model using ANOVA
anova(mod.qp, test='F')
#ok lets make some predictions quickly..
fit=fitted.values(mod.qp)
yrep<-as.data.frame(fit)
yrep$trt<-aphid2$trt
library(ggplot2)
ggplot()+
geom_boxplot(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))+
geom_point(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))
#negative binomial
library(MASS)
mod.nb <- glm.nb(n.aphids~trt, data=aphid2)
summary(mod.nb)
windows(); par(mfrow=c(2,2));plot(mod.nb)
#CMP
library(COMPoissonReg)
install.packages("COMPoissonReg")
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
#CMP
library(COMPoissonReg)
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
#compare coefficients of models
coef(mod1)
coef(mod.qp)
coef(mod.nb)
coef(mod.CMP)
#compare AIC values of models
AIC(mod1); AIC(mod.nb); AIC(mod.CMP)
#load the data and look at its structure
mydata <- read.csv("binary.csv",header=T,sep=" ")
## view the first few rows of the data
head(mydata)
summary(mydata)
str(mydata)
#NOTE: R is reading Rank as a numeric. We need to convert it to a factor. (In general, ALWAYS check the summary() statement or str() statment of imported data to make sure that your data columns are of the correct type.)
mydata$rank <- as.factor(mydata$rank)
#recheck the data
summary(mydata)
str(mydata)
mylogit <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
summary(mylogit)
anova(mylogit,test='Chisq')
par(mfrow=c(2,2)); plot(mylogit)
par(mfrow=c(2,2)); plot(mylogit)
# perform an overdispersion test (recall we compare residual chi-sq to the residual degrees of freedom)
chisq <- sum(resid(mylogit, type='pearson')^2)
chisq/df.residual(mylogit) ## close to 1; no overdispersion problem
library(arm)
?binnedplot
x <- predict(mylogit)
y <- resid(mylogit)
binnedplot(x,y)
x
null.logit <- glm(admit ~ 1, data = mydata, family = "binomial")
summary(null.logit)
dim(mydata)
anova(null.logit,mylogit,test="Chisq")
#now check the deviance explained by each parameter in the model
anova(mylogit,test="Chisq")
summary(mylogit)
mydata <- read.csv("binary.csv",header=T,sep=" ")
summary(mydata)
mydata$rank <- as.factor(mydata$rank)
mydata$rank
glm1 <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
summary(glm1)
glm2 <- glm(admit ~ gpa+rank, data = mydata, family = "binomial")
summary(glm2)
anova(glm1,glm2,test="Chisq")
AIC(glm1,glm2)
mydata <- read.csv("ceb.csv",header=T)
mydata
summary(mydata)
head(mydata)
mydata <- read.csv("ceb.csv",header=T)
mydata
summary(mydata)
head(mydata)
mydata <- read.csv("ceb.csv",header=T)
mydata
summary(mydata)
head(mydata)
#So now suppose we think education is a good predictor of the number of children a woman would have over the duration of her life. We can plot the counts for the number of children born to each woman for each education group, using ggplot().
ggplot(mydata, aes(mean, fill = educ)) + geom_histogram(binwidth = 0.5, position = "dodge")
#we can test this idea more formally using Poisson regression
